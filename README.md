# Order Processing Service

Sistema de Processamento de Pedidos para plataforma de e-commerce, construÃ­do com **Spring Boot**, **PostgreSQL** e **Apache Kafka**, com foco em **processamento assÃ­ncrono**, **observabilidade** e **testes automatizados**.

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura](#arquitetura)
- [Tecnologias](#tecnologias)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [Como Executar](#como-executar)
  - [1. Clonar o projeto](#1-clonar-o-projeto)
  - [2. Executar com Docker + Make (Linux/WSL)](#2-executar-com-docker--make-linuxwsl)
  - [3. Executar com Docker Compose](#3-executar-com-docker-compose)
  - [4. Desenvolvimento Local (sem Docker para a app)](#4-desenvolvimento-local-sem-docker-para-a-app)
- [Observabilidade e MÃ©tricas](#observabilidade-e-mÃ©tricas)
- [API Endpoints (Resumo)](#api-endpoints-resumo)
- [Tipos de Pedidos](#tipos-de-pedidos)
- [Eventos Kafka](#eventos-kafka)
- [Testes](#testes)
- [DecisÃµes de Design e Justificativas](#decisÃµes-de-design-e-justificativas)
- [Uso de IA](#uso-de-ia)
- [O que foi priorizado](#o-que-foi-priorizado)
- [O que eu melhoraria com mais tempo](#o-que-eu-melhoraria-com-mais-tempo)
- [VariÃ¡veis de Ambiente](#variÃ¡veis-de-ambiente)
- [Health Checks](#health-checks)
- [DocumentaÃ§Ã£o Adicional](#documentaÃ§Ã£o-adicional)
- [Autor](#autor)
- [LicenÃ§a](#licenÃ§a)

---

## VisÃ£o Geral

O sistema processa pedidos de forma **assÃ­ncrona**, suportando cinco tipos de produtos:

- **PHYSICAL**: Produtos fÃ­sicos com controle de estoque
- **SUBSCRIPTION**: Assinaturas recorrentes
- **DIGITAL**: Produtos digitais com licenciamento
- **PRE_ORDER**: PrÃ©-vendas de produtos nÃ£o lanÃ§ados
- **CORPORATE**: Pedidos B2B com regras especiais

O fluxo Ã© orientado a eventos: o pedido Ã© criado, um evento Ã© enviado para o Kafka e o processamento acontece em um **consumer** dedicado.

---

## Arquitetura

```txt
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚â”€â”€â”€â”€â–¶â”‚  REST API   â”‚â”€â”€â”€â”€â–¶â”‚ PostgreSQL  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚    Kafka    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Consumer   â”‚
                   â”‚ (Processor) â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
````

### Fluxo de Processamento

1. Cliente envia pedido via `POST /api/orders`.
2. Sistema valida o payload e calcula o valor total com base no catÃ¡logo.
3. Pedido Ã© salvo com status `PENDING`.
4. Evento `ORDER_CREATED` Ã© publicado no Kafka (`order-events`).
5. Consumer lÃª o evento e orquestra o processamento.
6. Regras por tipo de produto sÃ£o aplicadas (Strategy de `OrderItemProcessor`).
7. Status final Ã© atualizado para `PROCESSED`, `FAILED` ou `PENDING_APPROVAL`.
8. Eventos de resultado (`ORDER_PROCESSED`, `ORDER_FAILED`, etc.) sÃ£o publicados.

---

## Tecnologias

* **Java 21**
* **Spring Boot 3.3**
* **Spring Data JPA**
* **Spring Kafka**
* **PostgreSQL 16**
* **Apache Kafka**
* **Docker & Docker Compose**
* **Testcontainers**
* **Maven**

---

## PrÃ©-requisitos

* **Docker** e **Docker Compose** instalados
* **Make** (para usar os atalhos `make` em Linux/WSL)
* **Java 21+** e **Maven 3.9+** (se for rodar localmente sem Docker)

---

## Como Executar

### 1. Clonar o projeto

```bash
git clone https://github.com/humberto789/order-processing-service.git
cd order-processing-service
```

---

### 2. Executar com Docker + Make (Linux/WSL)

Atalhos pensados para desenvolvimento rÃ¡pido:

```bash
# Build das imagens e preparaÃ§Ã£o inicial
make setup

# Subir toda a infraestrutura (app + postgres + kafka + kafka-ui)
make up

# Ver logs da aplicaÃ§Ã£o
make logs

# Executar testes dentro do container
make test

# Derrubar infraestrutura
make down

# Limpar containers, imagens e volumes associados
make clean
```

---

### 3. Executar com Docker Compose

Se vocÃª estiver no Windows sem Make instalado, pode usar o Docker Compose diretamente.

```bash
# Subir todos os serviÃ§os (app, postgres, kafka, kafka-ui)
docker compose up --build -d

# Verificar status
docker compose ps

# Ver logs da aplicaÃ§Ã£o
docker compose logs -f order-processing-service-app

# Derrubar tudo
docker compose down
```

A aplicaÃ§Ã£o ficarÃ¡ disponÃ­vel em:

* API: `http://localhost:8080`
* Kafka UI: `http://localhost:8081` (se configurado no `docker-compose.yml`)

---

### 4. Desenvolvimento Local (sem Docker para a app)

Rodando dependÃªncias em Docker e a aplicaÃ§Ã£o no seu ambiente Java:

```bash
# Subir apenas PostgreSQL e Kafka
docker compose up -d postgres kafka zookeeper

# Rodar a aplicaÃ§Ã£o localmente
mvn spring-boot:run

# Exemplo com variÃ¡veis de ambiente
DB_HOST=localhost \
KAFKA_BOOTSTRAP_SERVERS=localhost:9092 \
mvn spring-boot:run
```

---

## Observabilidade e MÃ©tricas

* **Health**: `http://localhost:8080/actuator/health`
* **MÃ©tricas (lista)**: `http://localhost:8080/actuator/metrics`
* **MÃ©trica especÃ­fica**: `http://localhost:8080/actuator/metrics/{nome}`
* **Formato Prometheus**: `http://localhost:8080/actuator/prometheus`

MÃ©tricas de negÃ³cio expostas (via `OrderMetricsService`):

* `orders.created.total`
* `orders.amount`
* `orders.processed.total{status=...}`
* `orders.failed.total{reason=...}`
* `orders.items.processed.total{product_type=...}`
* `orders.high_value.total` / `orders.high_value.amount`
* `orders.fraud_alert.total` / `orders.fraud_alert.amount`
* `inventory.low_stock.total{product_id=...}`
* `orders.processing.duration{status=...}`

Mais detalhes em [`docs/METRICS-GUIDE.md`](./docs/METRICS-GUIDE.md).

---

## API Endpoints (Resumo)

### Criar Pedido

```http
POST /api/orders
Content-Type: application/json

{
  "customerId": "customer-123",
  "items": [
    {
      "productId": "BOOK-CC-001",
      "quantity": 2,
      "metadata": {
        "warehouseLocation": "SP"
      }
    }
  ]
}
```

**Resposta (201 Created):**

```json
{
  "orderId": 1,
  "status": "PENDING",
  "totalAmount": 179.80,
  "createdAt": "2025-01-15T10:30:00Z"
}
```

### Consultar Pedido

```http
GET /api/orders/{orderId}
```

**Resposta (200 OK):**

```json
{
  "orderId": 1,
  "customerId": "customer-123",
  "items": [...],
  "totalAmount": 179.80,
  "status": "PROCESSED",
  "createdAt": "2025-01-15T10:30:00Z",
  "updatedAt": "2025-01-15T10:30:05Z"
}
```

### Listar Pedidos por Cliente

```http
GET /api/orders?customerId={customerId}&page=0&size=20
```

---

## Tipos de Pedidos

### PHYSICAL (Produtos FÃ­sicos)

* Verifica disponibilidade em estoque
* Reserva quantidade no inventÃ¡rio
* Gera alerta de estoque baixo (`LOW_STOCK_ALERT`) se < 5 unidades
* Calcula prazo de entrega

### SUBSCRIPTION (Assinaturas)

* MÃ¡ximo de 5 assinaturas ativas por cliente
* Bloqueia duplicidade do mesmo produto
* Regras de compatibilidade entre planos

### DIGITAL (Produtos Digitais)

* Verifica disponibilidade de licenÃ§as
* Bloqueia compra duplicada
* Gera chave de ativaÃ§Ã£o Ãºnica

### PRE_ORDER (PrÃ©-vendas)

* Valida se data de lanÃ§amento Ã© futura
* Verifica slots de prÃ©-venda disponÃ­veis
* Aplica descontos especÃ­ficos

### CORPORATE (Pedidos Corporativos)

* Exige CNPJ
* Limite de crÃ©dito configurado
* Pedidos altos podem exigir aprovaÃ§Ã£o manual (`ORDER_PENDING_APPROVAL`)
* Descontos progressivos por volume

---

## Eventos Kafka

### TÃ³pico: `order-events`

| Evento                   | DescriÃ§Ã£o                               |
| ------------------------ | --------------------------------------- |
| `ORDER_CREATED`          | Pedido criado, aguardando processamento |
| `ORDER_PROCESSED`        | Pedido processado com sucesso           |
| `ORDER_FAILED`           | Falha no processamento                  |
| `ORDER_PENDING_APPROVAL` | Aguardando aprovaÃ§Ã£o manual             |
| `LOW_STOCK_ALERT`        | Alerta de estoque baixo                 |
| `FRAUD_ALERT`            | Alerta de possÃ­vel fraude               |

---

## Testes

```bash
# Executar todos os testes
make test

# Ou diretamente com Maven
mvn test

# Testes com relatÃ³rio de cobertura
mvn test jacoco:report
```

### Tipos de testes

* **Testes de IntegraÃ§Ã£o** com Testcontainers (PostgreSQL/Kafka)
* **Testes UnitÃ¡rios** para lÃ³gica de negÃ³cio e processadores
* ValidaÃ§Ã£o estÃ¡tica com **Checkstyle** (qualidade de cÃ³digo)

---

## DecisÃµes de Design e Justificativas

### Arquitetura em camadas + eventos

* **Por quÃª?** MantÃ©m o cÃ³digo organizado (API â†’ DomÃ­nio â†’ Infra) e facilita evoluir para microserviÃ§os se o sistema crescer.
* **Trade-off:** Mais componentes (Kafka, consumers) que um CRUD simples, mas muito mais alinhado a um cenÃ¡rio real de e-commerce.

### Processamento orientado a eventos (Kafka)

* **MotivaÃ§Ã£o:** Permitir processamento assÃ­ncrono, reprocessamento e integraÃ§Ã£o com outros serviÃ§os.
* **DecisÃ£o:** Publicar eventos de ciclo de vida do pedido (`ORDER_CREATED`, `ORDER_PROCESSED`, etc.) e deixar o consumer responsÃ¡vel pelas regras de negÃ³cio.
* **Alternativa descartada:** processamento totalmente sÃ­ncrono diretamente no controller (acoplaria a experiÃªncia do cliente a toda a lÃ³gica de backoffice).

### Strategy para processadores de itens

* **MotivaÃ§Ã£o:** Cada tipo de produto tem regras muito diferentes.
* **DecisÃ£o:** Implementar um `OrderItemProcessor` por `ProductType` e fazer o dispatch de forma centralizada.
* **BenefÃ­cio:** Fica fÃ¡cil adicionar um novo tipo de produto sem explodir um `if` gigante.

### CatÃ¡logo de produtos em memÃ³ria

* **MotivaÃ§Ã£o:** Evitar um serviÃ§o adicional sÃ³ para o desafio.
* **DecisÃ£o:** Implementar um catÃ¡logo in-memory para simular consulta de preÃ§os e atributos.
* **EvoluÃ§Ã£o natural:** migrar para uma tabela/serviÃ§o de catÃ¡logo real, incluindo cache e versionamento de preÃ§o.

### Observabilidade desde o inÃ­cio

* **MotivaÃ§Ã£o:** Saber o que o sistema estÃ¡ fazendo Ã© tÃ£o importante quanto â€œfuncionarâ€.
* **DecisÃ£o:** ExpÃ´r mÃ©tricas de negÃ³cio (volume, falhas, tipos de itens, fraude, low stock) e tÃ©cnicas (HTTP, JVM, etc.) via Actuator.
* **BenefÃ­cio:** Com poucas queries Ã© possÃ­vel montar dashboards Ãºteis para produto e operaÃ§Ã£o.

Mais detalhes de arquitetura em `/docs` (ADRs e system design).

---

## Uso de IA

### Ferramentas

- **ChatGPT (OpenAI)**: apoio na escrita e refino de:
    - DocumentaÃ§Ã£o (`README`, ADRs, mÃ©tricas)
    - OrganizaÃ§Ã£o de cÃ³digo e nomes
    - Ideias iniciais de estrutura de mÃ³dulos e boas prÃ¡ticas

- **Claude (Anthropic)**: utilizado para:
    - GeraÃ§Ã£o de cÃ³digos base e exemplos de implementaÃ§Ã£o
    - Alternativas de design para partes especÃ­ficas da aplicaÃ§Ã£o
    - SugestÃµes de refatoraÃ§Ã£o e melhorias pontuais

- **GitHub Copilot (plugin no IntelliJ)**: utilizado para:
    - Autocomplete de trechos de cÃ³digo repetitivos
    - SugestÃ£o de pequenas funÃ§Ãµes e snippets simples
    - GeraÃ§Ã£o inicial de comentÃ¡rios e Javadocs, depois revisados

### Como foi utilizado

- As ferramentas de IA foram usadas como **parceiras de brainstorming**, nÃ£o como geradoras do projeto inteiro.
- ChatGPT e Claude ajudaram principalmente em:
    - Esqueleto inicial de algumas classes e serviÃ§os
    - Exemplos de uso de Micrometer/Actuator e padrÃµes de projeto
    - Escrita e revisÃ£o de documentaÃ§Ã£o em portuguÃªs e inglÃªs
- O GitHub Copilot foi usado para:
    - Acelerar escrita de cÃ³digo em pontos mais mecÃ¢nicos
    - Completar padrÃµes jÃ¡ estabelecidos no projeto (builders, logs, validaÃ§Ãµes)

### ValidaÃ§Ã£o do cÃ³digo gerado

- Todo cÃ³digo sugerido por IA (ChatGPT, Claude ou Copilot) foi:
    - **Revisado manualmente** antes de entrar no projeto.
    - **Adaptado ao padrÃ£o do cÃ³digo existente** (nomes de pacotes, enums, exceÃ§Ãµes, estilo).
    - **Validado com**:
        - Testes unitÃ¡rios e de integraÃ§Ã£o (`mvn test`).
        - Ferramentas estÃ¡ticas (**Checkstyle**, **SonarLint**).
        - ExecuÃ§Ã£o local da aplicaÃ§Ã£o, verificando logs e endpoints (`/actuator/health`, `/actuator/metrics`).

- Nenhum trecho foi â€œcopiado Ã s cegasâ€: a responsabilidade final pelo design, pelas decisÃµes de arquitetura e pela implementaÃ§Ã£o Ã© minha.

---

## O que foi priorizado

1. **Fluxo de processamento de pedidos claro e robusto**

    * Estados bem definidos (`PENDING`, `PROCESSED`, `FAILED`, `PENDING_APPROVAL`).
    * Tratamento consistente de erros de negÃ³cio vs erros inesperados.

2. **DomÃ­nio e regras de negÃ³cio bem modelados**

    * Tipos de produtos com regras prÃ³prias.
    * Falhas categorizadas (`OrderFailureReason`).

3. **Observabilidade**

    * MÃ©tricas de negÃ³cio para explicar o comportamento real do sistema.
    * Health checks personalizados para garantir registradores por tipo.

4. **Testes**

    * Garantir que o fluxo principal de criaÃ§Ã£o e processamento funcione ponta a ponta.
    * Uso de Testcontainers para aproximar do ambiente real (PostgreSQL/Kafka).

5. **DocumentaÃ§Ã£o**

    * README utilizÃ¡vel por outra pessoa desenvolvedora.
    * Documentos em `/docs` explicando arquitetura e decisÃµes.

---

## O que eu melhoraria com mais tempo

Se tivesse mais tempo para evoluir este projeto, eu focaria em:

1. **MicroserviÃ§os reais**

    * Separar `order-service`, `catalog-service`, `inventory-service` e `notification-service`.
    * Uso de um API Gateway e versionamento de APIs.

2. **SeguranÃ§a e autenticaÃ§Ã£o**

    * AutenticaÃ§Ã£o via JWT/OAuth2.
    * AutorizaÃ§Ã£o por escopo/role nas operaÃ§Ãµes sensÃ­veis.
    * RevisÃ£o de LGPD (dados pessoais em logs, payloads e banco).

3. **ResiliÃªncia**

    * Implementar retries com backoff, DLQs e mecanismos de deduplicaÃ§Ã£o de eventos.

4. **Admin/Backoffice**

    * UI simples para acompanhar pedidos, aprovar/reprovar `PENDING_APPROVAL`.
    * Tela de monitoramento de mÃ©tricas de negÃ³cio.

5. **Mais testes**

    * Mais cenÃ¡rios de nÃ£o-happy-path e casos limite (volume, concorrÃªncia).
    * Testes de contrato para eventos Kafka.

---

## VariÃ¡veis de Ambiente

| VariÃ¡vel                  | DescriÃ§Ã£o           | PadrÃ£o       |
| ------------------------- | ------------------- | ------------ |
| `DB_HOST`                 | Host do PostgreSQL  | `postgres`   |
| `DB_PORT`                 | Porta do PostgreSQL | `5432`       |
| `DB_NAME`                 | Nome do banco       | `orders_db`  |
| `DB_USER`                 | UsuÃ¡rio do banco    | `orders`     |
| `DB_PASSWORD`             | Senha do banco      | `orders`     |
| `KAFKA_BOOTSTRAP_SERVERS` | Brokers Kafka       | `kafka:9092` |
| `SERVER_PORT`             | Porta da aplicaÃ§Ã£o  | `8080`       |

---

## Health Checks

* **AplicaÃ§Ã£o:** `http://localhost:8080/actuator/health`
* **MÃ©tricas:** `http://localhost:8080/actuator/metrics`
* **Kafka UI (quando habilitado):** `http://localhost:8081`

---

## DocumentaÃ§Ã£o Adicional

Toda documentaÃ§Ã£o detalhada estÃ¡ em `/docs`:

* `EXECUTIVE-SUMMARY.md` â€“ visÃ£o geral do projeto.
* `ADR-001` a `ADR-005` â€“ decisÃµes de arquitetura.
* `system-design.md` â€“ design de componentes e fluxos.
* `METRICS-GUIDE.md` â€“ guia completo das mÃ©tricas.

---

## Autor

Desenvolvido como parte de um desafio tÃ©cnico, por **Humberto Vitalino da Silva Neto**.

---

## LicenÃ§a

Este projeto Ã© privado e destinado apenas para avaliaÃ§Ã£o tÃ©cnica.